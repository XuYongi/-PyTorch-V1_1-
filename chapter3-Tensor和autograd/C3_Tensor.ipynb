{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's begin\n",
    "from __future__ import print_function\n",
    "import torch  as t\n",
    "t.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                               表3-1: 常见新建tensor的方法\n",
    "\n",
    "|函数|功能|\n",
    "|:---:|:---:|\n",
    "|Tensor(\\*sizes)|基础构造函数|\n",
    "|tensor(data,)|类似np.array的构造函数|\n",
    "|ones(\\*sizes)|全1Tensor|\n",
    "|zeros(\\*sizes)|全0Tensor|\n",
    "|eye(\\*sizes)|对角线为1，其他为0|\n",
    "|arange(s,e,step|从s到e，步长为step|\n",
    "|linspace(s,e,steps)|从s到e，均匀切分成steps份|\n",
    "|rand/randn(\\*sizes)|均匀/标准分布|\n",
    "|normal(mean,std)/uniform(from,to)|正态分布/均匀分布|\n",
    "|randperm(m)|随机排列|\n",
    "\n",
    "这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4679e-27,  4.5790e-41,  4.6374e+21],\n",
       "        [ 4.5790e-41, -3.2188e-27,  4.5790e-41]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Tensor(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.arange(1, 6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  5.5000, 10.0000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.linspace(1, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0987,  0.2006, -1.4611],\n",
       "        [-0.2608, -0.4850, -1.6730]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.randn(2, 3, device=t.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 2, 4, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.randperm(5) # 长度为5的随机排列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t.tensor 与 np.array 使用方法几乎完全一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用tensor操作\n",
    "tensor.view方法可以调整tensor的形状，但必须保证调整前后元素总数一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0, 6)\n",
    "a.view(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(-1, 3) # 当某一维为-1的时候，会自动计算它的大小\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.unsqueeze(1) # 注意形状，在第1维（下标从0开始）上增加“１” \n",
    "#等价于 b[:,None]\n",
    "b.shape\n",
    "b[:, None].shape\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2]],\n",
       "\n",
       "        [[3],\n",
       "         [4],\n",
       "         [5]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[                  0,                   1,                   2],\n",
       "        [                  3,                   4,                   5],\n",
       "        [4189022128297176677, 4049408095958349090, 3759768343418449254]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(3, 3) # 旧的数据依旧保存着，多出的大小会分配新空间\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None类似于np.newaxis, 为a新增了一个轴\n",
    "# 等价于a.view(1, a.shape[0], a.shape[1])\n",
    "b[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b > 1 #有点强，得到mask\n",
    "# 等价于a.masked_select(a>1)\n",
    "# 选择结果与原tensor不共享内存空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([                  2,                   3,                   4,\n",
       "                          5, 4189022128297176677, 4049408095958349090,\n",
       "        3759768343418449254])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[b>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[t.LongTensor([0,1])]  #第0行和第1行  longtensor as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 6],\n",
       "        [ 9],\n",
       "        [12]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0, 16).view(4, 4)\n",
    "print(a)\n",
    "t.gather(a,1,t.tensor([[3,2,1,0]]).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 1, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t.tensor([[3,2,1,0]]))\n",
    "t.gather(a,0,t.tensor([[0,1,2,3]]))\n",
    "a.gather(0,t.tensor([[0,1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  3],\n",
       "        [ 5,  6],\n",
       "        [10,  9],\n",
       "        [15, 12]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = t.tensor([[0,1,2,3],[3,2,1,0]]).t()\n",
    "b = a.gather(1,index)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  3],\n",
       "        [ 0,  5,  6,  0],\n",
       "        [ 0,  9, 10,  0],\n",
       "        [12,  0,  0, 15]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = t.zeros(4,4,dtype=t.long)\n",
    "print(c)\n",
    "c.scatter_(1, index, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0,27).view(3,3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.Tensor(2,3)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把a转成FloatTensor，等价于b=a.type(t.FloatTensor)\n",
    "b = a.float()\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4679e-27,  4.5790e-41,  4.5471e+21],\n",
      "        [ 4.5790e-41, -3.2188e-27,  4.5790e-41]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4679e-27,  4.5790e-41,  4.5471e+21],\n",
       "        [ 4.5790e-41, -3.2188e-27,  4.5790e-41]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.type_as(b)\n",
    "print(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.zeros_like(a) #等价于t.zeros(a.shape,dtype=a.dtype,device=a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.new_ones(4,5, dtype=t.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.new_ones(4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逐元素操作\n",
    "\n",
    "这部分操作会对tensor的每一个元素(point-wise，又名element-wise)进行操作，此类操作的输入与输出形状一致。常用的操作如表3-4所示。\n",
    "\n",
    "表3-4: 常见的逐元素操作\n",
    "\n",
    "|函数|功能|\n",
    "|:--:|:--:|\n",
    "|abs/sqrt/div/exp/fmod/log/pow..|绝对值/平方根/除法/指数/求余/求幂..|\n",
    "|cos/sin/asin/atan2/cosh..|相关三角函数|\n",
    "|ceil/round/floor/trunc| 上取整/四舍五入/下取整/只保留整数部分|\n",
    "|clamp(input, min, max)|超过min和max部分截断|\n",
    "|sigmod/tanh..|激活函数\n",
    "\n",
    "对于很多操作，例如div、mul、pow、fmod等，PyTorch都实现了运算符重载，所以可以直接使用运算符。如`a ** 2` 等价于`torch.pow(a,2)`, `a * 2`等价于`torch.mul(a,2)`。\n",
    "\n",
    "其中`clamp(x, min, max)`的输出满足以下公式：\n",
    "$$\n",
    "y_i =\n",
    "\\begin{cases}\n",
    "min,  & \\text{if  } x_i \\lt min \\\\\n",
    "x_i,  & \\text{if  } min \\le x_i \\le max  \\\\\n",
    "max,  & \\text{if  } x_i \\gt max\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "`clamp`常用在某些需要比较大小的地方，如取一个tensor的每个元素与另一个数的较大值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.5403, -0.4161],\n",
       "        [-0.9900, -0.6536,  0.2837]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0., 6.).view(2, 3)\n",
    "t.cos(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.ones(2, 3)\n",
    "b.sum(dim = 0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keepdim=False，不保留维度\"1\"，注意形状\n",
    "b.sum(dim=0, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  3],\n",
       "        [ 3,  7, 12]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0, 6).view(2, 3)\n",
    "print(a)\n",
    "a.cumsum(dim=1) # 沿着行累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.,  6.],\n",
       "        [ 9., 12., 15.]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.linspace(0, 15, 6).view(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 12.,  9.],\n",
       "        [ 6.,  3.,  0.]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.linspace(15, 0, 6).view(2, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a>b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 12., 15.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 12.,  9.],\n",
       "        [ 9., 12., 15.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性代数\n",
    "PyTorch的线性函数主要封装了Blas和Lapack，其用法和接口都与之类似。常用的线性代数函数如表3-7所示。\n",
    "\n",
    "表3-7: 常用的线性代数函数\n",
    "\n",
    "|函数|功能|\n",
    "|:---:|:---:|\n",
    "|trace|对角线元素之和(矩阵的迹)|\n",
    "|diag|对角线元素|\n",
    "|triu/tril|矩阵的上三角/下三角，可指定偏移量|\n",
    "|mm/bmm|矩阵乘法，batch的矩阵乘法|\n",
    "|addmm/addbmm/addmv/addr/badbmm..|矩阵运算\n",
    "|t|转置|\n",
    "|dot/cross|内积/外积\n",
    "|inverse|求逆矩阵\n",
    "|svd|奇异值分解\n",
    "\n",
    "具体使用说明请参见官方文档[^3]，需要注意的是，矩阵的转置会导致存储空间不连续，需调用它的.contiguous方法将其转为连续。 [^3]: http://pytorch.org/docs/torch.html#blas-and-lapack-operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.t()\n",
    "b.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  9.],\n",
       "        [ 3., 12.],\n",
       "        [ 6., 15.]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Tensor和Numpy\n",
    "\n",
    "Tensor和Numpy数组之间具有很高的相似性，彼此之间的互操作也非常简单高效。需要注意的是，Numpy和Tensor共享内存。由于Numpy历史悠久，支持丰富的操作，所以当遇到Tensor不支持的操作时，可先转成Numpy数组，处理后再转回tensor，其转换开销很小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones([2, 3],dtype=np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.Tensor(a) # 也可以直接将numpy对象传入Tensor\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1., 100.,   1.],\n",
       "        [  1.,   1.,   1.]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, 1]=100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.,   1.],\n",
       "       [  1.,   1.,   1.]], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.numpy() # a, b, c三个对象共享内存\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**： 当numpy的数据类型和Tensor的类型不一样的时候，数据会被复制，不会共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones([2, 3])\n",
    "# 注意和上面的a的区别（dtype不是float32）\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.Tensor(a) # 此处进行拷贝，不共享内存\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = t.from_numpy(a) # 注意c的类型（DoubleTensor）\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, 1] = 100\n",
    "b # b与a不共享内存，所以即使a改变了，b也不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1., 100.,   1.],\n",
       "        [  1.,   1.,   1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：** 不论输入的类型是什么，t.tensor都会进行数据拷贝，不会共享内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**广播法则(broadcast)** 是科学运算中经常使用的一个技巧，它在快速执行向量化的同时不会占用额外的内存/显存。\n",
    "Numpy的广播法则定义如下：\n",
    "\n",
    "- 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分通过在前面加1补齐\n",
    "- 两个数组要么在某一个维度的长度一致，要么其中一个为1，否则不能计算 \n",
    "- 当输入数组的某个维度的长度为1时，计算时沿此维度复制扩充成一样的形状\n",
    "\n",
    "PyTorch当前已经支持了自动广播法则，但是笔者还是建议读者通过以下两个函数的组合手动实现广播法则，这样更直观，更不易出错：\n",
    "\n",
    "- `unsqueeze`或者`view`，或者tensor[None],：为数据某一维的形状补1，实现法则1\n",
    "- `expand`或者`expand_as`，重复数组，实现法则3；该操作不会复制数组，所以不会占用额外的空间。\n",
    "\n",
    "注意，repeat实现与expand相类似的功能，但是repeat会把相同数据复制多份，因此会占用额外的空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 内部结构\n",
    "\n",
    "tensor的数据结构如图3-1所示。tensor分为头信息区(Tensor)和存储区(Storage)，信息区主要保存着tensor的形状（size）、步长（stride）、数据类型（type）等信息，而真正的数据则保存成连续数组。由于数据动辄成千上万，因此信息区元素占用内存较少，主要内存占用则取决于tensor中元素的数目，也即存储区的大小。\n",
    "\n",
    "一般来说一个tensor有着与之相对应的storage, storage是在data之上封装的接口，便于使用，而不同tensor的头信息一般不同，但却可能使用相同的数据。下面看两个例子。\n",
    "\n",
    "![图3-1: Tensor的数据结构](imgs/tensor_data_structure.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU\n",
    "tensor可以很随意的在gpu/cpu上传输。使用`tensor.cuda(device_id)`或者`tensor.cpu()`。另外一个更通用的方法是`tensor.to(device)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.randn(3, 4)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "        [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "        [ 0.0473,  0.2572,  1.4273, -0.0139]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if t.cuda.is_available():\n",
    "    a = t.randn(3,4, device=t.device('cuda:0'))\n",
    "    # 等价于\n",
    "    # a.t.randn(3,4).cuda(1)\n",
    "    # 但是前者更快\n",
    "    a.device\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "        [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "        [ 0.0473,  0.2572,  1.4273, -0.0139]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = t.device('cpu')\n",
    "a.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**\n",
    "- 尽量使用`tensor.to(device)`, 将`device`设为一个可配置的参数，这样可以很轻松的使程序同时兼容GPU和CPU\n",
    "- 数据在GPU之中传输的速度要远快于内存(CPU)到显存(GPU), 所以尽量避免频繁的在内存和显存中传输数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持久化\n",
    "Tensor的保存和加载十分的简单，使用t.save和t.load即可完成相应的功能。在save/load时可指定使用的`pickle`模块，在load时还可将GPU tensor映射到CPU或其它GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "         [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "         [ 0.0473,  0.2572,  1.4273, -0.0139]], device='cuda:0'),\n",
       " tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "         [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "         [ 0.0473,  0.2572,  1.4273, -0.0139]], device='cuda:0'),\n",
       " tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "         [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "         [ 0.0473,  0.2572,  1.4273, -0.0139]]),\n",
       " tensor([[ 1.4113, -1.3038,  0.8454,  0.9498],\n",
       "         [-1.1213, -0.1662,  0.2636, -1.9777],\n",
       "         [ 0.0473,  0.2572,  1.4273, -0.0139]], device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if t.cuda.is_available():\n",
    "    a = a.cuda(0) # 把a转为GPU1上的tensor,\n",
    "    t.save(a,'a.pth')\n",
    "\n",
    "    # 加载为b, 存储于GPU1上(因为保存时tensor就在GPU1上)\n",
    "    b = t.load('a.pth')\n",
    "    # 加载为c, 存储于CPU\n",
    "    c = t.load('a.pth', map_location=lambda storage, loc: storage)\n",
    "    # 加载为d, 存储于GPU0上\n",
    "    d = t.load('a.pth', map_location={'cuda:1':'cuda:0'})\n",
    "a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 668 µs per loop\n",
      "The slowest run took 8.77 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10 loops, best of 3: 3.01 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def for_loop_add(x, y):\n",
    "    result = []\n",
    "    for i,j in zip(x, y):\n",
    "        result.append(i + j)\n",
    "    return t.Tensor(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.zeros(100)\n",
    "y = t.ones(100)\n",
    "%timeit -n 10 for_loop_add(x, y)\n",
    "%timeit -n 10 x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外还有以下几点需要注意：\n",
    "- 大多数`t.function`都有一个参数`out`，这时候产生的结果将保存在out指定tensor之中。\n",
    "- `t.set_num_threads`可以设置PyTorch进行CPU多线程并行计算时候所占用的线程数，这个可以用来限制PyTorch所占用的CPU数目。\n",
    "- `t.set_printoptions`可以用来设置打印tensor时的数值精度和格式。\n",
    "下面举例说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19999999) tensor(19999998)\n",
      "tensor(16777216.) tensor(16777216.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(19999999), tensor(19999998))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.arange(0, 20000000)\n",
    "print(a[-1], a[-2]) # 32bit的IntTensor精度\n",
    "a = t.arange(0, 20000000.0)\n",
    "print(a[-1], a[-2]) # 32bit的IntTensor精度有限导致溢出\n",
    "b = t.LongTensor()\n",
    "t.arange(0, 20000000.0, out=b) # 64bit的LongTensor不会溢出\n",
    "b[-1],b[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0502, -1.0743, -1.9176],\n",
       "        [ 0.7633, -0.0517,  0.7622]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.randn(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0501508713, -1.0742504597, -1.9176168442],\n",
       "        [ 0.7633384466, -0.0517239533,  0.7622276545]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_printoptions(precision=10)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归是机器学习入门知识，应用十分广泛。线性回归利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的，其表达形式为$y = wx+b+e$，$e$为误差服从均值为0的正态分布。首先让我们来确认线性回归的损失函数：\n",
    "$$\n",
    "loss = \\sum_i^N \\frac 1 2 ({y_i-(wx_i+b)})^2\n",
    "$$\n",
    "然后利用随机梯度下降法更新参数$\\textbf{w}$和$\\textbf{b}$来最小化损失函数，最终学得$\\textbf{w}$和$\\textbf{b}$的数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "device = t.device('cpu') #如果你想用gpu，改成t.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证在不同电脑上运行时下面的输出一致\n",
    "t.manual_seed(1000) \n",
    "\n",
    "def get_fake_data(batch_size=8):\n",
    "    ''' 产生随机数据：y=x*2+3，加上了一些噪声'''\n",
    "    x = t.rand(batch_size, 1, device=device) * 5\n",
    "    y = x * 2 + 3 +  t.randn(batch_size, 1, device=device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb2a80f1320>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生的x-y分布\n",
    "x, y = get_fake_data(batch_size=16)\n",
    "plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  1.986863374710083 b:  2.9016706943511963\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化参数\n",
    "w = t.rand(1, 1).to(device)\n",
    "b = t.zeros(1, 1).to(device)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "for ii in range(500):\n",
    "    x,y = get_fake_data(batch_size=4)\n",
    "    \n",
    "    #foaward：计算loss\n",
    "    y_pred = x.mm(w) + b.expand_as(y)\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    #backward: 手动计算梯度\n",
    "    dloss = 1\n",
    "    dy_pred = dloss * ( y_pred - y)\n",
    "    \n",
    "    dw = x.t().mm(dy_pred)\n",
    "    db = dy_pred.sum()\n",
    "    \n",
    "    # 更新参数\n",
    "    w.sub_(lr * dw)\n",
    "    b.sub_(lr * db)\n",
    "    \n",
    "    if ii%50 ==0:\n",
    "\n",
    "    # 画图\n",
    "        display.clear_output(wait=True)\n",
    "        x = t.arange(0, 6.0).view(-1, 1)\n",
    "        y = x.mm(w) + b.expand_as(x)\n",
    "        plt.plot(x.cpu().numpy(), y.cpu().numpy()) # predicted\n",
    "\n",
    "        x2, y2 = get_fake_data(batch_size=32) \n",
    "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
    "\n",
    "        plt.xlim(0, 5)\n",
    "        plt.ylim(0, 13)\n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "        \n",
    "print('w: ', w.item(), 'b: ', b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
